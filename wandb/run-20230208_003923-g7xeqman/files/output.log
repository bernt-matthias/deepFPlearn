Splitting data with seed 856170991
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5919/5919 [00:00<00:00, 10189.02it/s]
Total scaffolds = 1,775 | train scaffolds = 1,219 | val scaffolds = 333 | test scaffolds = 223
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 1,414 | target average = 0.048091
Scaffold 1
Task 0: count = 1,164 | target average = 0.103952
Scaffold 2
Task 0: count = 80 | target average = 0.025000
Scaffold 3
Task 0: count = 54 | target average = 0.037037
Scaffold 4
Task 0: count = 53 | target average = 0.169811
Scaffold 5
Task 0: count = 44 | target average = 0.295455
Scaffold 6
Task 0: count = 37 | target average = 1.000000
Scaffold 7
Task 0: count = 36 | target average = 1.000000
Scaffold 8
Task 0: count = 33 | target average = 0.333333
Scaffold 9
Task 0: count = 30 | target average = 0.266667
Class sizes
AR 0: 82.11%, 1: 17.89%
Total size = 5,919 | train size = 4,735 | val size = 591 | test size = 593
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|                                                                                                                                                                                                    | 0/1 [00:00<?, ?it/s]Epoch 0
                                                                                                                                                                                                                               Loss = 5.3497e-01, PNorm = 34.0146, GNorm = 0.6222, lr_0 = 1.5266e-04
  9%|█████████████████▋                                                                                                                                                                         | 9/95 [00:00<00:06, 12.38it/s]
 20%|█████████████████████████████████████▏                                                                                                                                                    | 19/95 [00:01<00:07, 10.28it/s]Loss = 4.1068e-01, PNorm = 34.0222, GNorm = 1.2375, lr_0 = 2.4840e-04
 31%|████████████████████████████████████████████████████████▊                                                                                                                                 | 29/95 [00:02<00:05, 12.24it/s]
 41%|████████████████████████████████████████████████████████████████████████████▎                                                                                                             | 39/95 [00:03<00:04, 12.72it/s]Loss = 4.3648e-01, PNorm = 34.0409, GNorm = 0.4563, lr_0 = 3.4415e-04
 52%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                          | 49/95 [00:04<00:03, 12.90it/s]Loss = 3.8421e-01, PNorm = 34.0590, GNorm = 0.7970, lr_0 = 3.9202e-04
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 59/95 [00:05<00:03, 11.00it/s]Loss = 4.0949e-01, PNorm = 34.0696, GNorm = 0.6992, lr_0 = 4.3989e-04
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 69/95 [00:05<00:02, 12.03it/s]Loss = 3.9158e-01, PNorm = 34.0826, GNorm = 0.4817, lr_0 = 4.8777e-04
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                               | 79/95 [00:06<00:01, 10.86it/s]
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 89/95 [00:07<00:00, 12.26it/s]

Validation prc-auc = 0.625273
Training binary_cross_entropy = 0.412792
Training prc-auc = 0.775900
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:12<00:00, 12.16s/it]
Model 0 best validation binary_cross_entropy = 0.651734 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test binary_cross_entropy = 0.533219
Model 0 test AR binary_cross_entropy = 0.533219
Model 0 test prc-auc = 0.731126
Model 0 test AR prc-auc = 0.731126
Ensemble test binary_cross_entropy = 0.533219
Ensemble test AR binary_cross_entropy = 0.533219
Ensemble test prc-auc = 0.731126
Ensemble test AR prc-auc = 0.731126
Fold 1