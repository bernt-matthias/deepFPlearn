Splitting data with seed 838224289
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5919/5919 [00:00<00:00, 10107.85it/s]
Total scaffolds = 1,775 | train scaffolds = 1,184 | val scaffolds = 279 | test scaffolds = 312
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 1,414 | target average = 0.048091
Scaffold 1
Task 0: count = 1,164 | target average = 0.103952
Scaffold 2
Task 0: count = 80 | target average = 0.025000
Scaffold 3
Task 0: count = 54 | target average = 0.037037
Scaffold 4
Task 0: count = 53 | target average = 0.169811
Scaffold 5
Task 0: count = 44 | target average = 0.295455
Scaffold 6
Task 0: count = 37 | target average = 1.000000
Scaffold 7
Task 0: count = 36 | target average = 1.000000
Scaffold 8
Task 0: count = 33 | target average = 0.333333
Scaffold 9
Task 0: count = 30 | target average = 0.266667
Class sizes
AR 0: 82.11%, 1: 17.89%
Total size = 5,919 | train size = 4,735 | val size = 591 | test size = 593
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|                                                                                                                                                                                                    | 0/1 [00:00<?, ?it/s]Epoch 0
                                                                                                                                                                                                                               Loss = 5.4220e-01, PNorm = 34.0144, GNorm = 0.6095, lr_0 = 1.5266e-04
  8%|███████████████▋                                                                                                                                                                           | 8/95 [00:00<00:06, 12.67it/s]
 19%|███████████████████████████████████▏                                                                                                                                                      | 18/95 [00:01<00:08,  9.43it/s]Loss = 4.9562e-01, PNorm = 34.0217, GNorm = 0.2712, lr_0 = 2.4840e-04
 29%|██████████████████████████████████████████████████████▊                                                                                                                                   | 28/95 [00:02<00:05, 11.96it/s]
 40%|██████████████████████████████████████████████████████████████████████████▍                                                                                                               | 38/95 [00:03<00:04, 12.31it/s]Loss = 4.6072e-01, PNorm = 34.0436, GNorm = 0.5540, lr_0 = 3.4415e-04
 51%|█████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                            | 48/95 [00:04<00:03, 12.13it/s]
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                        | 58/95 [00:05<00:03, 10.77it/s]Loss = 4.4093e-01, PNorm = 34.0694, GNorm = 1.1723, lr_0 = 4.3989e-04
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 68/95 [00:05<00:02, 12.02it/s]Loss = 3.5229e-01, PNorm = 34.0754, GNorm = 0.9291, lr_0 = 4.8777e-04
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 78/95 [00:06<00:01, 12.17it/s]
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎             | 88/95 [00:07<00:00, 12.28it/s]

 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎             | 88/95 [00:07<00:00, 12.28it/s]Validation binary_cross_entropy = 0.477976
Validation prc-auc = 0.719065
Training binary_cross_entropy = 0.386780
Training prc-auc = 0.769962
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:12<00:00, 12.19s/it]
Model 0 best validation binary_cross_entropy = 0.477976 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test binary_cross_entropy = 0.534552
Model 0 test AR binary_cross_entropy = 0.534552
Model 0 test prc-auc = 0.647744
Model 0 test AR prc-auc = 0.647744
Ensemble test binary_cross_entropy = 0.534552
Ensemble test AR binary_cross_entropy = 0.534552
Ensemble test prc-auc = 0.647744
Ensemble test AR prc-auc = 0.647744
Fold 1